# -*- coding: utf-8 -*-
"""can_counter.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UklZaIzm11mDUffJGVMNcDUJcbTcEm3U
"""

from google.colab import drive
drive.mount('/content/drive')

"""Install requirements"""

!pip install ultralytics==8.0.184
from ultralytics import YOLO
import ultralytics
ultralytics.checks()

"""Detection"""

from ultralytics import YOLO
model = YOLO('/content/drive/MyDrive/Can/TS-divyanshi/Cans/Yolov8_detection/can_yolov8m_det_640_v0/weights/best.pt')
model.predict(source="/content/drive/MyDrive/Can/TS-divyanshi/Cans/Can_data/can_video/WhatsApp Video 2024-03-13 at 17.10.05_236f90ff.mp4", save=True, imgsz=320, conf=0.5)

"""# **Tracker**"""

from ultralytics import YOLO
model = YOLO('/content/drive/MyDrive/Can/TS-divyanshi/Cans/Yolov8_detection/can_yolov8m_det_640_v0/weights/best.pt')
results = model.track(source="/content/drive/MyDrive/Can/TS-divyanshi/Cans/can.mp4", show=True, stream=True)

for r in results:
    boxes = r.boxes
    masks = r.masks
    probs = r.probs
    # print(boxes)
    # print(masks)
    # print(probs)

import cv2
import numpy as np
from google.colab.patches import cv2_imshow
image_path = '/content/yolo_can_annotated_data_80/images/can-2024_03_13-12_50_08-frame_26.jpg'
img = cv2.imread(image_path)
def draw_polygon(img):
    pts = [np.array([[912, 705], [905, 550], [870, 553], [877, 707], [911, 705]])]
    image = cv2.polylines(img, pts, True, (0, 255, 0), 2)
    return image
polygon_img = draw_polygon(img)
cv2_imshow(polygon_img)

import numpy as np
from ultralytics import YOLO
import cv2
from collections import defaultdict

import cv2

from ultralytics.utils.checks import check_imshow, check_requirements
from ultralytics.utils.plotting import Annotator, colors

check_requirements("shapely>=2.0.0")

from shapely.geometry import LineString, Point, Polygon


class ObjectCounter:
    """A class to manage the counting of objects in a real-time video stream based on their tracks."""

    def __init__(self):
        """Initializes the Counter with default values for various tracking and counting parameters."""

        # Mouse events
        self.is_drawing = False
        self.selected_point = None

        # Region & Line Information
        self.reg_pts = [(20, 400), (1260, 400)]
        self.line_dist_thresh = 15
        self.counting_region = None
        self.region_color = (255, 0, 255)
        self.region_thickness = 5

        # Image and annotation Information
        self.im0 = None
        self.tf = None
        self.view_img = False
        self.view_in_counts = True
        self.view_out_counts = True

        self.names = None  # Classes names
        self.annotator = None  # Annotator
        self.window_name = "Ultralytics YOLOv8 Object Counter"

        # Object counting Information
        self.in_counts = 0
        self.out_counts = 0
        self.counting_dict = {}
        self.count_txt_thickness = 0
        self.count_txt_color = (0, 0, 0)
        self.count_color = (255, 255, 255)

        # Tracks info
        self.track_history = defaultdict(list)
        self.track_thickness = 2
        self.draw_tracks = False
        self.track_color = (0, 255, 0)

        # Check if environment support imshow
        self.env_check = check_imshow(warn=True)

    def set_args(
        self,
        classes_names,
        reg_pts,
        count_reg_color=(255, 0, 255),
        line_thickness=2,
        track_thickness=2,
        view_img=False,
        view_in_counts=True,
        view_out_counts=True,
        draw_tracks=False,
        count_txt_thickness=2,
        count_txt_color=(0, 0, 0),
        count_color=(255, 255, 255),
        track_color=(0, 255, 0),
        region_thickness=5,
        line_dist_thresh=15,
    ):
        self.tf = line_thickness
        self.view_img = view_img
        self.view_in_counts = view_in_counts
        self.view_out_counts = view_out_counts
        self.track_thickness = track_thickness
        self.draw_tracks = draw_tracks

        if len(reg_pts) == 2:
            print("Line Counter Initiated.")
            self.reg_pts = reg_pts
            self.counting_region = LineString(self.reg_pts)
        elif len(reg_pts) >= 3:
            print("Region Counter Initiated.")
            self.reg_pts = reg_pts
            self.counting_region = Polygon(self.reg_pts)
        else:
            print("Invalid Region points provided, region_points must be 2 for lines or >= 3 for polygons.")
            print("Using Line Counter Now")
            self.counting_region = LineString(self.reg_pts)

        self.names = classes_names
        self.track_color = track_color
        self.count_txt_thickness = count_txt_thickness
        self.count_txt_color = count_txt_color
        self.count_color = count_color
        self.region_color = count_reg_color
        self.region_thickness = region_thickness
        self.line_dist_thresh = line_dist_thresh

    def mouse_event_for_region(self, event, x, y, flags, params):
        if event == cv2.EVENT_LBUTTONDOWN:
            for i, point in enumerate(self.reg_pts):
                if (
                    isinstance(point, (tuple, list))
                    and len(point) >= 2
                    and (abs(x - point[0]) < 10 and abs(y - point[1]) < 10)
                ):
                    self.selected_point = i
                    self.is_drawing = True
                    break

        elif event == cv2.EVENT_MOUSEMOVE:
            if self.is_drawing and self.selected_point is not None:
                self.reg_pts[self.selected_point] = (x, y)
                self.counting_region = Polygon(self.reg_pts)

        elif event == cv2.EVENT_LBUTTONUP:
            self.is_drawing = False
            self.selected_point = None

    def extract_and_process_tracks(self, tracks):
        self.annotator = Annotator(self.im0, self.tf, self.names)

        if tracks[0].boxes.id is not None:
            boxes = tracks[0].boxes.xyxy.cpu()
            clss = tracks[0].boxes.cls.cpu().tolist()

            # Extract tracks
            for box, cls in zip(boxes, clss):
                # Draw bounding box
                self.annotator.box_label(box, label=f"can", color=colors(int(cls), True))

                if tracks[0].boxes.id is not None:
                    boxes = tracks[0].boxes.xyxy.cpu()
                    clss = tracks[0].boxes.cls.cpu().tolist()
                    track_ids = tracks[0].boxes.id.int().cpu().tolist()

                    # Extract tracks
                    for box, track_id, cls in zip(boxes, track_ids, clss):
                        # Draw bounding box
                        self.annotator.box_label(box, label=f"{self.names[cls]}", color=colors(int(cls), True))

                        # Draw Tracks
                        track_line = self.track_history[track_id]
                        track_line.append((float((box[0] + box[2]) / 2), float((box[1] + box[3]) / 2)))
                        if len(track_line) > 30:
                            track_line.pop(0)

                        # Draw track trails
                        if self.draw_tracks:
                            self.annotator.draw_centroid_and_tracks(
                                track_line, color=self.track_color, track_thickness=self.track_thickness
                            )

                        prev_position = self.track_history[track_id][-2] if len(self.track_history[track_id]) > 1 else None
                        centroid = Point((box[:2] + box[2:]) / 2)

                        # Count objects
                        if len(self.reg_pts) >= 3:  # any polygon
                            is_inside = self.counting_region.contains(centroid)
                            current_position = "in" if is_inside else "out"

                            if prev_position is not None:
                                if self.counting_dict[track_id] != current_position and is_inside:
                                    self.in_counts += 1
                                    self.counting_dict[track_id] = "in"
                                elif self.counting_dict[track_id] != current_position and not is_inside:
                                    self.out_counts += 1
                                    self.counting_dict[track_id] = "out"
                                else:
                                    self.counting_dict[track_id] = current_position

                            else:
                                self.counting_dict[track_id] = current_position

                        elif len(self.reg_pts) == 2:
                            if prev_position is not None:
                                is_inside = (box[0] - prev_position[0]) * (
                                    self.counting_region.centroid.x - prev_position[0]
                                ) > 0
                                current_position = "in" if is_inside else "out"

                                if self.counting_dict[track_id] != current_position and is_inside:
                                    self.in_counts += 1
                                    self.counting_dict[track_id] = "in"
                                elif self.counting_dict[track_id] != current_position and not is_inside:
                                    self.out_counts += 1
                                    self.counting_dict[track_id] = "out"
                                else:
                                    self.counting_dict[track_id] = current_position
                            else:
                                self.counting_dict[track_id] = None


    def display_frames(self):
        """Display frame."""
        if self.env_check:
            self.annotator.draw_region(reg_pts=self.reg_pts, color=self.region_color, thickness=self.region_thickness)
            cv2.namedWindow(self.window_name)
            if len(self.reg_pts) == 4:  # only add mouse event If user drawn region
                cv2.setMouseCallback(self.window_name, self.mouse_event_for_region, {"region_points": self.reg_pts})
            cv2.imshow(self.window_name, self.im0)
            # Break Window
            if cv2.waitKey(1) & 0xFF == ord("q"):
                return

    def start_counting(self, im0, tracks):
        self.im0 = im0  # store image
        self.extract_and_process_tracks(tracks)  # draw region even if no objects

        if self.view_img:
            self.display_frames()
        return self.im0

model = YOLO('/content/drive/MyDrive/Can/TS-divyanshi/Cans/Yolov8_detection/can_yolov8m_det_640_v0/weights/best.pt')

cap = cv2.VideoCapture("/content/drive/MyDrive/Can/TS-divyanshi/Cans/can.mp4")
assert cap.isOpened(), "Error reading video file"
w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))
fps = 5.0
region_points = [(912, 705), (870, 553), (877, 707), (911, 705)]
pts = np.array([[912, 705], [905, 550], [870, 553], [877, 707], [911, 705]], np.int32)  # Convert to numpy array

video_writer = cv2.VideoWriter("object_counting_output.mp4",
                               cv2.VideoWriter_fourcc(*'mp4v'),
                               fps,
                               (w, h))

counter = ObjectCounter()
counter.set_args(view_img=True,
                 reg_pts=region_points,
                 classes_names=model.names,
                 draw_tracks=False)

while cap.isOpened():
    success, frame = cap.read()

    if success:
        tracks = model.track(frame, persist=True, show=False)

        cv2.polylines(frame, [pts], isClosed=True, color=(0, 255, 0), thickness=2)  # Draw the polygon

        annotated_frame = counter.start_counting(frame, tracks)

        total_count = counter.in_counts
        count_label = f"Count: {total_count}"

        # Draw white background behind count label
        text_size = cv2.getTextSize(count_label, cv2.FONT_HERSHEY_SIMPLEX, 1, 19)[0]
        cv2.rectangle(annotated_frame, (20, 20), (20 + text_size[0], 20 + text_size[1]), (255, 255, 255), -1)

        # Overlay count label
        cv2.putText(annotated_frame, count_label, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, cv2.LINE_AA)

        video_writer.write(annotated_frame)
    else:
        break

cap.release()
video_writer.release()
cv2.destroyAllWindows()

!mkdir -p res

!cp '/content/drive/MyDrive/Can/TS-divyanshi/Cans/Can_data/logo.jpg' '/content'

import cv2
import os

input_path = r'/content/res'
filename = 'object_counting_output.mp4'


logo_path = r'/content/logo.jpg'
watermark = cv2.imread(logo_path)
wy, wx = watermark.shape[:2]

alpha = 0.75

# for filename in os.listdir(input_path):
#     if len(filename.split('.')) > 1:
#         if  filename.split('.')[1] == 'mp4' and filename not in {name for name in os.listdir(input_path+'/output')}:


cap = cv2.VideoCapture(input_path+'/'+filename)

_, frame = cap.read()
y, x = frame.shape[:2]
# frame = frame[0:y-100]#, 0:x-100]
y, x = frame.shape[:2]

print(y,x)

fourcc = cv2.VideoWriter_fourcc(*'MP4V')
# vid_writer = cv2.VideoWriter(input_path+'/output/'+filename, fourcc, 30.0, (x,y))
vid_writer = cv2.VideoWriter(r'/content/res/canpred_logo.mp4', fourcc, 5.0, (x,y))



while cap.isOpened():
    _, frame = cap.read()
    if frame is not None:

        y, x = frame.shape[:2]
        # frame = frame[0:y-100]#, 0:x-100]
        img = frame.copy()


        y, x = frame.shape[:2]

        frame[y-wy-20:y-20, x-wx-20:x-20] = watermark

        image_new = cv2.addWeighted(frame, alpha, img, 1 - alpha, 0)

        vid_writer.write(image_new)

        # cv2.imshow("Display", image_new)
        # if cv2.waitKey(1) == ord('q'):  # q to quit
        #     raise StopIteration

    else:
        vid_writer.release()
        print('done')
        break

# Commented out IPython magic to ensure Python compatibility.
# %cp -r '/content/res' '/content/drive/MyDrive/Can/TS-divyanshi/Cans/Can_data'

"""# **Different code**"""

from ultralytics import YOLO
from ultralytics.utils.ops import scale_image
import cv2
import numpy as np
import os
from tqdm import tqdm
from google.colab.patches import cv2_imshow
from collections import defaultdict

def is_point_inside_polygon(x, y, poly):
    n = len(poly)
    inside = False

    p1x, p1y = poly[0]
    for i in range(n + 1):
        p2x, p2y = poly[i % n]
        if y > min(p1y, p2y):
            if y <= max(p1y, p2y):
                if x <= max(p1x, p2x):
                    if p1y != p2y:
                        xinters = (y - p1y) * (p2x - p1x) / (p2y - p1y) + p1x
                    if p1x == p2x or x <= xinters:
                        inside = not inside
        p1x, p1y = p2x, p2y

    return inside

def process_image(img):
    # img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # cv2_imshow(img)
    return img

video_folder = '/content/video'
save_video = '/content/res'
os.makedirs(save_video, exist_ok=True)

model = YOLO("/content/drive/MyDrive/TS-divyanshi/Cans/Yolov8_detection/can_yolov8m_det_640_v0/weights/best.pt")

col = Colors()



polygon_coordinates = [[893, 703], [885, 537], [898, 538], [909, 698], [910, 706], [890, 700]]
cords = np.array([[893, 703], [885, 537], [898, 538], [909, 698], [910, 706], [890, 700]], np.int32)

# def count_cans_in_polygon(boxes, track_ids):
#     cans_inside_polygon = set()
#     for box, track_id in zip(boxes, track_ids):
#         x1, y1, x2, y2 = map(int, box)
#         # Check if any point of the bounding box is inside the polygon
#         if any(is_point_inside_polygon(x, y, polygon_coordinates) for x, y in [(x1, y1), (x1, y2), (x2, y1), (x2, y2)]):
#             cans_inside_polygon.add(track_id)
#     return cans_inside_polygon

def count_cans_in_polygon(boxes, track_ids):
    cans_inside_polygon = set()
    for box, track_id in zip(boxes, track_ids):
        x1, y1, x2, y2 = map(int, box)
        for x in range(x1, x2 + 1):
            for y in range(y1, y2 + 1):
                if is_point_inside_polygon(x, y, polygon_coordinates):
                    cans_inside_polygon.add(track_id)
                    break
            else:
                continue
            break
    return cans_inside_polygon

def predict_on_image(model, img, conf):
    # result = model(img, conf=conf, agnostic_nms=True, classes=0)[0]
    result = model.track(img, imgsz=640, conf=conf, agnostic_nms=True, classes=0, persist=True)[0]

    if result is not None:
        # detection
        cls = result.boxes.cls
        probs = result.boxes.conf.cpu().numpy()
        boxes = result.boxes.xyxy.cpu().numpy()

        if result.boxes.id is None:
            pass
        else:
            track_ids = result.boxes.id.cpu().numpy().astype(int)

    else:
        boxes, cls, probs, track_ids = [], [], [], []

    return boxes, cls, probs, track_ids
unique_cans_inside_polygon = set()
for files in tqdm(os.listdir(video_folder)):
    video_path = os.path.join(video_folder, files)
    cap = cv2.VideoCapture(video_path)
    frame_width = int(cap.get(3))
    frame_height = int(cap.get(4))
    save_video_path = os.path.join(save_video, files)

    out = cv2.VideoWriter(save_video_path, cv2.VideoWriter_fourcc(*'MP4V'), 5, (frame_width, frame_height))

    track_history = defaultdict(lambda: [])
    frame_cnt = 0

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        processed_frame = process_image(frame)

        boxes, cls, probs, track_ids = predict_on_image(model, processed_frame, conf=0.25)
        frame_cnt += 1

        if len(boxes) > 0:
            image_with_masks = np.copy(processed_frame)
            cans_id = count_cans_in_polygon(boxes, track_ids)
            unique_cans_inside_polygon.update(cans_id)
            print("Unique cans inside polygon:",len(unique_cans_inside_polygon), unique_cans_inside_polygon)
            for i, (box, track_id) in enumerate(zip(boxes, track_ids)):
                cls_i = int(cls[i])
                prob = probs[i]
                x1, y1, x2, y2 = map(int, box)
                track = track_history[track_id]
                track.append((float(x1), float(y1)))
                if len(track) > 15:
                    track.pop(0)
                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)

                # text = f" ({track_id})"
                text = 'Can'
                cv2.rectangle(image_with_masks, (x1, y1), (x2, y2), col.Red, 1)
                cv2.rectangle(image_with_masks, (x1, y1 - 15), (x2, y1), col.Gray, -1)
                cv2.putText(image_with_masks, text, (x1, y1), cv2.FONT_HERSHEY_PLAIN, 1, col.White, 1)


            count_text = f'Count: {len(unique_cans_inside_polygon)}'
            text_size = cv2.getTextSize(count_text, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)[0]
            cv2.rectangle(image_with_masks, (20, 30 - text_size[1]), (20 + text_size[0], 30), col.White, -1)
            cv2.putText(image_with_masks, count_text, (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)

            cv2.polylines(image_with_masks, [cords], isClosed=True, color=(0, 255, 0), thickness=2)

            out.write(image_with_masks)
            print(frame_cnt)
            # cv2_imshow(image_with_masks)
            # break
    cap.release()
    out.release()
    cv2.destroyAllWindows()